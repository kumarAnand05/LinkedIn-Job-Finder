# LinkedIn Job Finder
<img align="right" width="100" height="100" src="https://user-images.githubusercontent.com/111251492/225376166-b814df59-814b-448e-b85d-90f3a7ee4ac6.png">
By Anand Kumar


## Features
* **Fast Scrapping** : Quickly extracts job data from LinkedIn
* **Advanced Job description filtering** : Scans each job description, filters out jobs whose description doesn't matches your experience.
* **Reduced bot action detection** :  Mitigates the risk of being detected as a bot during data scraping.


### ⚠️NOTE : 
I want to make it clear that I strongly discourage any attempts to scrape data from LinkedIn. If anyone is considering such actions, I urge them to first review [LinkedIn's official policy](https://www.linkedin.com/help/linkedin/answer/a1341387/prohibition-of-scraping-software?lang=en-us&intendedLocale=en) regarding the use of scraping software, as outlined in their statement. This project was carried out as a implementation of knowledge during my learning journey and not to use the the LinkedIn data for any unauthorized usage and this project should not be used for any attempt to do so.

# Instructions
After you have downloaded the project files. Follow the instructions below to setup your machine to make code functional.
## Downloading/Installing dependencies
Of course you need [JDK](https://www.oracle.com/in/java/technologies/downloads/) and an IDE like [VSCode](https://code.visualstudio.com), [IntelliJ](https://www.jetbrains.com/idea/) etc. installed on your machine.

> Download Dependencies

Open the project in your IDE and connect to internet. Using the pom.xml file present in the project directory, download the dependencies by performing specific actions for the IDE that you are using. 

###### Your machine is ready now!!!

Simply open the whole Job scraper folder in your IDE and run the Main.java file to start LinkedIn Job Scraper. After entering the required input in the console, the browser will automatically begin scraping job listings based on the specified criteria. The browser closes automatically after the code completes running successfully.

## Dos and Don'ts
> Do's

+ You can use your machine during the process.
+ You can keep the browser and IDE in background.

> Don'ts

+ Do not click on any element of the webpage as it can lead to termination of the code.
+ Do not use console during the process.
+ Do not turn off internet or close the automated browser session.
+ To prevent any unexpected action against your LinkedIn account, please do not have your browser logged in to LinkedIn which you are going to automate. Care to logout before running the scraper.
